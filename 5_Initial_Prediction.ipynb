{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from surprise import SVD\n",
    "from surprise import SVDpp\n",
    "from surprise import NMF\n",
    "from surprise import KNNBasic\n",
    "from surprise import KNNWithZScore\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "from surprise.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_seed = 0\n",
    "random.seed(my_seed)\n",
    "np.random.seed(my_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data set with Normalized Purchase\n",
    "User_Prod_NP = pd.read_csv('./Files_Folder/User_Prod_NormPurc.csv')\n",
    "\n",
    "# Statistics of each Product_ID in train data sets\n",
    "train_Prod_sta = pd.read_csv('./Files_Folder/train_User_Prod_stat.csv') \n",
    "\n",
    "# Statistics of new Product_IDs; those are Prodcut_IDs in test data set but not in train data set\n",
    "New_Prod_LUT = pd.read_csv('./Files_Folder/New_Product_Details.csv')\n",
    "\n",
    "# Test Data Set\n",
    "test_data_sub = pd.read_csv('./Files_Folder/test_data_sub.csv')\n",
    "\n",
    "# Hold Out Data Set\n",
    "hold_data_sub = pd.read_csv('./Files_Folder/hold_data_sub.csv')\n",
    "\n",
    "# Train Data Set\n",
    "train_data = pd.read_csv('./Files_Folder/train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 3 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Mean    Std     \n",
      "RMSE (testset)    0.8849  0.8834  0.8820  0.8834  0.0012  \n",
      "MAE (testset)     0.6989  0.6983  0.6958  0.6977  0.0013  \n",
      "Fit time          129.04  130.33  124.48  127.95  2.51    \n",
      "Test time         1.34    1.35    1.37    1.35    0.01    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.88494019, 0.88342689, 0.88197835]),\n",
       " 'test_mae': array([0.69894886, 0.69825194, 0.69584483]),\n",
       " 'fit_time': (129.03629350662231, 130.3284363746643, 124.47913932800293),\n",
       " 'test_time': (1.3436517715454102, 1.3451571464538574, 1.3657407760620117)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo_SVD = SVD(n_epochs=130, lr_all = 0.005, reg_all = 0.1)\n",
    "\n",
    "# A reader is still needed but only the rating_scale param is required.\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "data = Dataset.load_from_df(User_Prod_NP[['User_ID', 'Product_ID', 'Normalized_Purchase']], reader)\n",
    "\n",
    "# We can now use this dataset as we please, e.g. calling cross_validate\n",
    "cross_validate(algo_SVD, data, cv=3, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_prod = list(New_Prod_LUT.Product_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Normalized_Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.950620e+05</td>\n",
       "      <td>495062.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.003027e+06</td>\n",
       "      <td>3.538755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.727099e+03</td>\n",
       "      <td>1.082961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000001e+06</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.001514e+06</td>\n",
       "      <td>2.955803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.003075e+06</td>\n",
       "      <td>3.887335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.004473e+06</td>\n",
       "      <td>4.035739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.006040e+06</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            User_ID  Normalized_Purchase\n",
       "count  4.950620e+05        495062.000000\n",
       "mean   1.003027e+06             3.538755\n",
       "std    1.727099e+03             1.082961\n",
       "min    1.000001e+06             1.000000\n",
       "25%    1.001514e+06             2.955803\n",
       "50%    1.003075e+06             3.887335\n",
       "75%    1.004473e+06             4.035739\n",
       "max    1.006040e+06             5.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "User_Prod_NP.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of unique Product IDs in test data set =  2819\n",
      "Shape of test data set using unique Product ID as filter =  (27503, 11)\n",
      "# of unique Product IDs in New Product (not present in Big Matrix) =  16\n",
      "Asociated Shape of the dataframe =  (8, 11)\n"
     ]
    }
   ],
   "source": [
    "k = list(test_data_sub.Product_ID.unique())\n",
    "print ('# of unique Product IDs in test data set = ', len(k))\n",
    "\n",
    "print ('Shape of test data set using unique Product ID as filter = ', test_data_sub[test_data_sub.Product_ID.isin(k)].shape)\n",
    "\n",
    "k1 = list(New_Prod_LUT.Product_ID.unique())\n",
    "print ('# of unique Product IDs in New Product (not present in Big Matrix) = ', len(k1))\n",
    "\n",
    "print ('Asociated Shape of the dataframe = ', test_data_sub[test_data_sub.Product_ID.isin(k1)].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data_sub_newid_shape =  (8, 11)\n",
      "test_data_sub_notnewid_shape =  (27495, 11)\n"
     ]
    }
   ],
   "source": [
    "test_data_sub_newid = test_data_sub[test_data_sub.Product_ID.isin(list(New_Prod_LUT.Product_ID.unique()))]\n",
    "print ('test_data_sub_newid_shape = ', test_data_sub_newid.shape)\n",
    "test_data_sub_newid.to_csv('./Files_Folder/test_data_sub_newid.csv')\n",
    "\n",
    "test_data_sub_notnewid = test_data_sub.drop(test_data_sub_newid.index)\n",
    "print ('test_data_sub_notnewid_shape = ', test_data_sub_notnewid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hold_data_sub_newid_shape =  (11, 11)\n",
      "hold_data_sub_notnewid_shape =  (27492, 11)\n"
     ]
    }
   ],
   "source": [
    "hold_data_sub_newid = hold_data_sub[hold_data_sub.Product_ID.isin(list(New_Prod_LUT.Product_ID.unique()))]\n",
    "print ('hold_data_sub_newid_shape = ', hold_data_sub_newid.shape)\n",
    "hold_data_sub_newid.to_csv('./Files_Folder/hold_data_sub_newid.csv')\n",
    "\n",
    "hold_data_sub_notnewid = hold_data_sub.drop(hold_data_sub_newid.index)\n",
    "print ('hold_data_sub_notnewid_shape = ', hold_data_sub_notnewid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using our model to predict the prices of the train data set\n",
    "# This is used to determine the training error\n",
    "train_user_list = []\n",
    "train_prod_list = []\n",
    "train_price = []\n",
    "for i in range(train_data.shape[0]):\n",
    "    p1 = algo_SVD.predict(train_data.User_ID[i],train_data.Product_ID[i]).est\n",
    "    rmin = train_Prod_sta.loc[3, train_data.Product_ID[i]]\n",
    "    rmax = train_Prod_sta.loc[7, train_data.Product_ID[i]]\n",
    "    dmin = 1\n",
    "    dmax = 5\n",
    "    p = (p1 - dmin)*(rmax - rmin)/(dmax - dmin) + rmin\n",
    "    train_price.append(p)\n",
    "    train_user_list.append(train_data.User_ID[i])\n",
    "    train_prod_list.append(train_data.Product_ID[i])\n",
    "final_train_tally = {'User_ID':train_user_list, 'Product_ID':train_prod_list, 'Purchase': train_price}\n",
    "final_train_tally_df = pd.DataFrame(final_train_tally)\n",
    "final_train_tally_df.to_csv('./Files_Folder/Predicted_train_Result_SVD.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting test data set. \n",
    "# New products are predicted using the median purchase of similar products based on their product categorizations \n",
    "test_user_list = []\n",
    "test_prod_list = []\n",
    "price = []\n",
    "for i in range(test_data_sub.shape[0]):\n",
    "    if test_data_sub.Product_ID[i] in new_prod:\n",
    "        p = New_Prod_LUT[New_Prod_LUT.Product_ID == test_data_sub.Product_ID[i]]['50%'].iloc[0]      \n",
    "    else:\n",
    "        p1 = algo_SVD.predict(test_data_sub.User_ID[i],test_data_sub.Product_ID[i]).est\n",
    "        rmin = train_Prod_sta.loc[3, test_data_sub.Product_ID[i]]\n",
    "        rmax = train_Prod_sta.loc[7, test_data_sub.Product_ID[i]]\n",
    "        dmin = 1\n",
    "        dmax = 5\n",
    "        p = (p1 - dmin)*(rmax - rmin)/(dmax - dmin) + rmin\n",
    "    price.append(p)\n",
    "    test_user_list.append(test_data_sub.User_ID[i])\n",
    "    test_prod_list.append(test_data_sub.Product_ID[i])\n",
    "final_tally = {'User_ID':test_user_list, 'Product_ID':test_prod_list, 'Purchase': price}\n",
    "final_tally_df = pd.DataFrame(final_tally)\n",
    "final_tally_df.to_csv('./Files_Folder/Predicted_test_SVD_median.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting test data set. \n",
    "# New products are predicted using the mean purchase of similar products based on their product categorizations\n",
    "test_user_list = []\n",
    "test_prod_list = []\n",
    "price = []\n",
    "for i in range(test_data_sub.shape[0]):\n",
    "    if test_data_sub.Product_ID[i] in new_prod:\n",
    "        p = New_Prod_LUT[New_Prod_LUT.Product_ID == test_data_sub.Product_ID[i]]['mean'].iloc[0]      \n",
    "    else:\n",
    "        p1 = algo_SVD.predict(test_data_sub.User_ID[i],test_data_sub.Product_ID[i]).est\n",
    "        rmin = train_Prod_sta.loc[3, test_data_sub.Product_ID[i]]\n",
    "        rmax = train_Prod_sta.loc[7, test_data_sub.Product_ID[i]]\n",
    "        dmin = 1\n",
    "        dmax = 5\n",
    "        p = (p1 - dmin)*(rmax - rmin)/(dmax - dmin) + rmin\n",
    "    price.append(p)\n",
    "    test_user_list.append(test_data_sub.User_ID[i])\n",
    "    test_prod_list.append(test_data_sub.Product_ID[i])\n",
    "final_tally = {'User_ID':test_user_list, 'Product_ID':test_prod_list, 'Purchase': price}\n",
    "final_tally_df = pd.DataFrame(final_tally)\n",
    "final_tally_df.to_csv('./Files_Folder/Predicted_test_SVD_mean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
